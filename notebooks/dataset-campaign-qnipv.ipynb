{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General thoughts\n",
    "- Use [qNIPV](https://github.com/facebook/Ax/issues/930) as acquisition fn to minimize\n",
    "  model error\n",
    "- store the raw sensor channel data, single-objective as the sum of all channels (maybe\n",
    "  best as ScalarizedObjective) or could be multi-objective\n",
    "- Run repeat experiments for each requested parameter set\n",
    "- Pass the standard deviation to Ax\n",
    "- For later, maybe base the hold-out performance on the input RGB differences instead of the target outputs\n",
    "- Using qNIPV means each datapoint is more valuable from a modeling perspective (OK that\n",
    "  it takes longer since it will likely be small compared to a real-world scenario)\n",
    "\n",
    "## Estimating distribution of targets\n",
    "- KDE, then fit a model that interpolates for a given quantile\n",
    "- fit quantiles across all experiments (model for lowest, model for 2nd lowest, etc.)\n",
    "- Is there a KDE for multiple inputs and a single response?\n",
    "- Use a heteroskedastic GP (probably run into scaling issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials in all campaigns: 2900\n",
      "Estimated campaign time: 8.1 hours\n"
     ]
    }
   ],
   "source": [
    "num_sobol = 10\n",
    "num_gpei = 0\n",
    "num_qnipv = 290\n",
    "num_repeats = 10 # i.e. how many times an individual experiment is repeated\n",
    "num_campaigns = 1 # i.e. how many campaigns are run (each with a different target)\n",
    "num_all_campaign_trials = (num_qnipv + num_gpei) * num_campaigns * num_repeats\n",
    "print(f\"Number of trials in all campaigns: {num_all_campaign_trials}\")\n",
    "time_per_trial_s = 10\n",
    "estimated_campaign_time = num_all_campaign_trials * time_per_trial_s / 3600\n",
    "print(f\"Estimated campaign time: {estimated_campaign_time:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "import json\n",
    "with open(\"secrets.json\", \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "MAIN_SEED = secrets[\"MAIN_SEED\"]\n",
    "rng = default_rng(seed=MAIN_SEED)\n",
    "SEEDS = rng.integers(low=0, high=1000000, size=num_campaigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'R', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'G', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'B', 'type': 'range', 'bounds': [0, 89]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from self_driving_lab_demo import SelfDrivingLabDemoLight, mqtt_observe_sensor_data\n",
    "\n",
    "sdls = [\n",
    "    SelfDrivingLabDemoLight(\n",
    "        target_seed=seed,\n",
    "        observe_sensor_data_fn=mqtt_observe_sensor_data,\n",
    "        observe_sensor_data_kwargs=dict(pico_id=\"test\", session_id=\"hackathon-dev\"),\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "]\n",
    "sdl = sdls[0]\n",
    "parameters = sdls[0].parameters[0:3]\n",
    "parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "from botorch.acquisition.input_constructors import (\n",
    "    MaybeDict,\n",
    "    acqf_input_constructor,\n",
    "    construct_inputs_mc_base,\n",
    ")\n",
    "\n",
    "from botorch.models.model import Model\n",
    "from botorch.utils.datasets import SupervisedDataset\n",
    "from torch import Tensor\n",
    "\n",
    "from botorch.acquisition.objective import AcquisitionObjective\n",
    "\n",
    "@acqf_input_constructor(qNegIntegratedPosteriorVariance)\n",
    "def construct_inputs_qNIPV(\n",
    "    model: Model,\n",
    "    mc_points: Tensor,\n",
    "    training_data: MaybeDict[SupervisedDataset],\n",
    "    objective: Optional[AcquisitionObjective] = None,\n",
    "    X_pending: Optional[Tensor] = None,\n",
    "    sampler: Optional[MCSampler] = None,\n",
    "    **kwargs: Any,\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    if model.num_outputs == 1:\n",
    "        objective = None\n",
    "\n",
    "    base_inputs = construct_inputs_mc_base(\n",
    "        model=model,\n",
    "        training_data=training_data,\n",
    "        sampler=sampler,\n",
    "        X_pending=X_pending,\n",
    "        objective=objective,\n",
    "    )\n",
    "\n",
    "    return {**base_inputs, \"mc_points\": mc_points}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 12-10 10:32:51] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89])], parameter_constraints=[]).\n",
      "[INFO 12-10 10:32:51] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 12-10 10:32:51] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 6 trials, GPEI for subsequent trials]). Iterations after 6 will take longer to generate due to  model-fitting.\n",
      "[INFO 12-10 10:32:51] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Due to non-specification, we will use the heuristic for selecting objective thresholds.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-10 10:32:51] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89])], parameter_constraints=[]).\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from ax.modelbridge import get_sobol\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
    "from ax.service.ax_client import AxClient\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "\n",
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ax_client_tmp = AxClient(torch_device=torch_device)\n",
    "ax_client_tmp.create_experiment(parameters=parameters)\n",
    "sobol = get_sobol(ax_client_tmp.experiment.search_space)\n",
    "mc_points = sobol.gen(1024).param_df.values\n",
    "mcp = torch.tensor(mc_points)\n",
    "\n",
    "model_kwargs_val = {\n",
    "    \"surrogate\": Surrogate(SingleTaskGP),\n",
    "    \"botorch_acqf_class\": qNegIntegratedPosteriorVariance,\n",
    "    \"acquisition_options\": {\"mc_points\": mcp},\n",
    "}\n",
    "\n",
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        GenerationStep(model=Models.SOBOL, num_trials=num_sobol),\n",
    "        GenerationStep(\n",
    "            model=Models.BOTORCH_MODULAR,\n",
    "            num_trials=num_qnipv,\n",
    "            model_kwargs=model_kwargs_val,\n",
    "        ),\n",
    "        # GenerationStep(model=Models.GPEI, num_trials=num_gpei),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ax_client = AxClient(generation_strategy=gs)\n",
    "ax_client.create_experiment(\n",
    "    name=\"clslab-light-experiment\",\n",
    "    parameters=parameters,\n",
    "    objectives={\n",
    "        ch_name: ObjectiveProperties(minimize=True) for ch_name in sdl.channel_names\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 12-10 10:40:11] ax.service.ax_client: Generated new trial 2 with parameters {'R': 85, 'G': 74, 'B': 38}.\n",
      "[INFO 12-10 10:40:15] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:15] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:15] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:15] ax.service.ax_client: Completed trial 2 with data: {'ch410': (493.0, None), 'ch440': (4586.0, None), 'ch470': (7736.0, None), 'ch510': (6926.0, None), 'ch550': (1245.0, None), 'ch583': (5380.0, None), 'ch620': (11398.0, None), 'ch670': (866.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694015.0, None)}.\n",
      "[INFO 12-10 10:40:15] ax.service.ax_client: Generated new trial 3 with parameters {'R': 60, 'G': 64, 'B': 57}.\n",
      "[INFO 12-10 10:40:21] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:21] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:21] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:21] ax.service.ax_client: Completed trial 3 with data: {'ch410': (511.0, None), 'ch440': (7579.0, None), 'ch470': (8960.0, None), 'ch510': (5959.0, None), 'ch550': (1156.0, None), 'ch583': (3672.0, None), 'ch620': (7627.0, None), 'ch670': (907.0, None), 'onboard_temperature_K': (297.8537, None), 'utc_timestamp': (1670694021.0, None)}.\n",
      "[INFO 12-10 10:40:21] ax.service.ax_client: Generated new trial 4 with parameters {'R': 5, 'G': 42, 'B': 49}.\n",
      "[INFO 12-10 10:40:26] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:26] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:26] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:26] ax.service.ax_client: Completed trial 4 with data: {'ch410': (325.0, None), 'ch440': (6329.0, None), 'ch470': (7072.0, None), 'ch510': (3572.0, None), 'ch550': (760.0, None), 'ch583': (436.0, None), 'ch620': (637.0, None), 'ch670': (665.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694026.0, None)}.\n",
      "[INFO 12-10 10:40:26] ax.service.ax_client: Generated new trial 5 with parameters {'R': 66, 'G': 66, 'B': 9}.\n",
      "[INFO 12-10 10:40:33] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:33] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:33] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:33] ax.service.ax_client: Completed trial 5 with data: {'ch410': (322.0, None), 'ch440': (902.0, None), 'ch470': (5166.0, None), 'ch510': (5922.0, None), 'ch550': (1047.0, None), 'ch583': (4006.0, None), 'ch620': (8408.0, None), 'ch670': (624.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694033.0, None)}.\n",
      "[INFO 12-10 10:40:33] ax.service.ax_client: Generated new trial 6 with parameters {'R': 53, 'G': 23, 'B': 11}.\n",
      "[INFO 12-10 10:40:38] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:38] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:38] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:38] ax.service.ax_client: Completed trial 6 with data: {'ch410': (212.0, None), 'ch440': (1010.0, None), 'ch470': (3077.0, None), 'ch510': (1444.0, None), 'ch550': (524.0, None), 'ch583': (3068.0, None), 'ch620': (6438.0, None), 'ch670': (479.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694039.0, None)}.\n",
      "[INFO 12-10 10:40:38] ax.service.ax_client: Generated new trial 7 with parameters {'R': 82, 'G': 74, 'B': 12}.\n",
      "[INFO 12-10 10:40:45] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:45] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:45] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:45] ax.service.ax_client: Completed trial 7 with data: {'ch410': (383.0, None), 'ch440': (1165.0, None), 'ch470': (5743.0, None), 'ch510': (6805.0, None), 'ch550': (1179.0, None), 'ch583': (5131.0, None), 'ch620': (10870.0, None), 'ch670': (701.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694045.0, None)}.\n",
      "[INFO 12-10 10:40:45] ax.service.ax_client: Generated new trial 8 with parameters {'R': 77, 'G': 44, 'B': 86}.\n",
      "[INFO 12-10 10:40:51] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:51] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:51] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:51] ax.service.ax_client: Completed trial 8 with data: {'ch410': (655.0, None), 'ch440': (12211.0, None), 'ch470': (10720.0, None), 'ch510': (4100.0, None), 'ch550': (1061.0, None), 'ch583': (4913.0, None), 'ch620': (10368.0, None), 'ch670': (1116.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694051.0, None)}.\n",
      "[INFO 12-10 10:40:51] ax.service.ax_client: Generated new trial 9 with parameters {'R': 32, 'G': 28, 'B': 17}.\n",
      "[INFO 12-10 10:40:56] ax.service.ax_client: Data was logged for metric onboard_temperature_K that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:56] ax.service.ax_client: Data was logged for metric utc_timestamp that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 12-10 10:40:56] ax.core.experiment: Attached data has some metrics ({'utc_timestamp', 'onboard_temperature_K'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 12-10 10:40:56] ax.service.ax_client: Completed trial 9 with data: {'ch410': (188.0, None), 'ch440': (1472.0, None), 'ch470': (3555.0, None), 'ch510': (1929.0, None), 'ch550': (553.0, None), 'ch583': (1581.0, None), 'ch620': (3189.0, None), 'ch670': (453.0, None), 'onboard_temperature_K': (297.3855, None), 'utc_timestamp': (1670694057.0, None)}.\n"
     ]
    },
    {
     "ename": "UnsupportedError",
     "evalue": "qNegIntegratedPosteriorVariance only supports ScalarizedObjective (DEPRECATED) type objectives.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m new_data\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     trial_params, trial_index \u001b[39m=\u001b[39m ax_client\u001b[39m.\u001b[39;49mget_next_trial()\n\u001b[0;32m     10\u001b[0m     data \u001b[39m=\u001b[39m evaluate(trial_params)\n\u001b[0;32m     11\u001b[0m     ax_client\u001b[39m.\u001b[39mcomplete_trial(\n\u001b[0;32m     12\u001b[0m         trial_index\u001b[39m=\u001b[39mtrial_index, raw_data\u001b[39m=\u001b[39mdata\n\u001b[0;32m     13\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\utils\\common\\executils.py:161\u001b[0m, in \u001b[0;36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             wait_interval \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\n\u001b[0;32m    158\u001b[0m                 MAX_WAIT_SECONDS, initial_wait_seconds \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    159\u001b[0m             )\n\u001b[0;32m    160\u001b[0m             time\u001b[39m.\u001b[39msleep(wait_interval)\n\u001b[1;32m--> 161\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m default_return_on_suppression\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\service\\ax_client.py:480\u001b[0m, in \u001b[0;36mAxClient.get_next_trial\u001b[1;34m(self, ttl_seconds, force)\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[39mraise\u001b[39;00m OptimizationShouldStop(message\u001b[39m=\u001b[39mglobal_stopping_message)\n\u001b[0;32m    478\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39mnew_trial(\n\u001b[1;32m--> 480\u001b[0m         generator_run\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gen_new_generator_run(), ttl_seconds\u001b[39m=\u001b[39mttl_seconds\n\u001b[0;32m    481\u001b[0m     )\n\u001b[0;32m    482\u001b[0m \u001b[39mexcept\u001b[39;00m MaxParallelismReachedException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_stopping_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\service\\ax_client.py:1606\u001b[0m, in \u001b[0;36mAxClient._gen_new_generator_run\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[39m# If random seed is not set for this optimization, context manager does\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \u001b[39m# nothing; otherwise, it sets the random seed for torch, but only for the\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m \u001b[39m# scope of this call. This is important because torch seed is set globally,\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m \u001b[39m# so if we just set the seed without the context manager, it can have\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \u001b[39m# serious negative impact on the performance of the models that employ\u001b[39;00m\n\u001b[0;32m   1604\u001b[0m \u001b[39m# stochasticity.\u001b[39;00m\n\u001b[0;32m   1605\u001b[0m \u001b[39mwith\u001b[39;00m manual_seed(seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_seed):\n\u001b[1;32m-> 1606\u001b[0m     \u001b[39mreturn\u001b[39;00m not_none(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgeneration_strategy)\u001b[39m.\u001b[39;49mgen(\n\u001b[0;32m   1607\u001b[0m         experiment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment,\n\u001b[0;32m   1608\u001b[0m         n\u001b[39m=\u001b[39;49mn,\n\u001b[0;32m   1609\u001b[0m         pending_observations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_pending_observation_features(\n\u001b[0;32m   1610\u001b[0m             experiment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\n\u001b[0;32m   1611\u001b[0m         ),\n\u001b[0;32m   1612\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\generation_strategy.py:334\u001b[0m, in \u001b[0;36mGenerationStrategy.gen\u001b[1;34m(self, experiment, data, n, pending_observations, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen\u001b[39m(\n\u001b[0;32m    298\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    299\u001b[0m     experiment: Experiment,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    304\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GeneratorRun:\n\u001b[0;32m    305\u001b[0m     \u001b[39m\"\"\"Produce the next points in the experiment. Additional kwargs passed to\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39m    this method are propagated directly to the underlying model's `gen`, along\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    with the `model_gen_kwargs` set on the current generation step.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39m            resuggesting points that are currently being evaluated.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gen_multiple(\n\u001b[0;32m    335\u001b[0m         experiment\u001b[39m=\u001b[39mexperiment,\n\u001b[0;32m    336\u001b[0m         num_generator_runs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    337\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[0;32m    338\u001b[0m         n\u001b[39m=\u001b[39mn,\n\u001b[0;32m    339\u001b[0m         pending_observations\u001b[39m=\u001b[39mpending_observations,\n\u001b[0;32m    340\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    341\u001b[0m     )[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\generation_strategy.py:475\u001b[0m, in \u001b[0;36mGenerationStrategy._gen_multiple\u001b[1;34m(self, experiment, num_generator_runs, data, n, pending_observations, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_generator_runs):\n\u001b[0;32m    474\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m         generator_run \u001b[39m=\u001b[39m _gen_from_generation_step(\n\u001b[0;32m    476\u001b[0m             generation_step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_curr,\n\u001b[0;32m    477\u001b[0m             input_max_gen_draws\u001b[39m=\u001b[39;49mMAX_GEN_DRAWS,\n\u001b[0;32m    478\u001b[0m             n\u001b[39m=\u001b[39;49mn,\n\u001b[0;32m    479\u001b[0m             pending_observations\u001b[39m=\u001b[39;49mpending_observations,\n\u001b[0;32m    480\u001b[0m             model_gen_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m    481\u001b[0m             should_deduplicate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_curr\u001b[39m.\u001b[39;49mshould_deduplicate,\n\u001b[0;32m    482\u001b[0m             arms_by_signature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49marms_by_signature,\n\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m         generator_run\u001b[39m.\u001b[39m_generation_step_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_curr\u001b[39m.\u001b[39mindex\n\u001b[0;32m    485\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator_runs\u001b[39m.\u001b[39mappend(generator_run)\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\generation_strategy.py:842\u001b[0m, in \u001b[0;36m_gen_from_generation_step\u001b[1;34m(input_max_gen_draws, generation_step, n, pending_observations, model_gen_kwargs, should_deduplicate, arms_by_signature)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m n_gen_draws \u001b[39m>\u001b[39m input_max_gen_draws:\n\u001b[0;32m    841\u001b[0m     \u001b[39mraise\u001b[39;00m GenerationStrategyRepeatedPoints(MAX_GEN_DRAWS_EXCEEDED_MESSAGE)\n\u001b[1;32m--> 842\u001b[0m generator_run \u001b[39m=\u001b[39m generation_step\u001b[39m.\u001b[39mgen(\n\u001b[0;32m    843\u001b[0m     n\u001b[39m=\u001b[39mn,\n\u001b[0;32m    844\u001b[0m     pending_observations\u001b[39m=\u001b[39mpending_observations,\n\u001b[0;32m    845\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_gen_kwargs,\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m should_generate_run \u001b[39m=\u001b[39m should_deduplicate \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    848\u001b[0m     arm\u001b[39m.\u001b[39msignature \u001b[39min\u001b[39;00m arms_by_signature \u001b[39mfor\u001b[39;00m arm \u001b[39min\u001b[39;00m generator_run\u001b[39m.\u001b[39marms\n\u001b[0;32m    849\u001b[0m )\n\u001b[0;32m    850\u001b[0m n_gen_draws \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\generation_node.py:165\u001b[0m, in \u001b[0;36mGenerationNode.gen\u001b[1;34m(self, n, pending_observations)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Picks a fitted model, from which to generate candidates (via\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m``self._pick_fitted_model_to_gen_from``) and generates candidates\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mfrom it. Uses the ``model_gen_kwargs`` set on the selected ``ModelSpec``\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39m    a generator run with number of arms (that can differ from ``n``).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m model_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_spec_to_gen_from\n\u001b[1;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m model_spec\u001b[39m.\u001b[39;49mgen(\n\u001b[0;32m    166\u001b[0m     \u001b[39m# If `n` is not specified, ensure that the `None` value does not\u001b[39;49;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# override the one set in `model_spec.model_gen_kwargs`.\u001b[39;49;00m\n\u001b[0;32m    168\u001b[0m     n\u001b[39m=\u001b[39;49mmodel_spec\u001b[39m.\u001b[39;49mmodel_gen_kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;49;00m n \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39mand\u001b[39;49;00m model_spec\u001b[39m.\u001b[39;49mmodel_gen_kwargs\n\u001b[0;32m    170\u001b[0m     \u001b[39melse\u001b[39;49;00m n,\n\u001b[0;32m    171\u001b[0m     \u001b[39m# For `pending_observations`, prefer the input to this function, as\u001b[39;49;00m\n\u001b[0;32m    172\u001b[0m     \u001b[39m# `pending_observations` are dynamic throughout the experiment and thus\u001b[39;49;00m\n\u001b[0;32m    173\u001b[0m     \u001b[39m# unlikely to be specified in `model_spec.model_gen_kwargs`.\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     pending_observations\u001b[39m=\u001b[39;49mpending_observations,\n\u001b[0;32m    175\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\model_spec.py:205\u001b[0m, in \u001b[0;36mModelSpec.gen\u001b[1;34m(self, **model_gen_kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m fitted_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_model\n\u001b[0;32m    198\u001b[0m model_gen_kwargs \u001b[39m=\u001b[39m consolidate_kwargs(\n\u001b[0;32m    199\u001b[0m     kwargs_iterable\u001b[39m=\u001b[39m[\n\u001b[0;32m    200\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_gen_kwargs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    203\u001b[0m     keywords\u001b[39m=\u001b[39mget_function_argument_names(fitted_model\u001b[39m.\u001b[39mgen),\n\u001b[0;32m    204\u001b[0m )\n\u001b[1;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m fitted_model\u001b[39m.\u001b[39mgen(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_gen_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\base.py:662\u001b[0m, in \u001b[0;36mModelBridge.gen\u001b[1;34m(self, n, search_space, optimization_config, pending_observations, fixed_features, model_gen_options)\u001b[0m\n\u001b[0;32m    654\u001b[0m base_gen_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_transformed_gen_args(\n\u001b[0;32m    655\u001b[0m     search_space\u001b[39m=\u001b[39msearch_space,\n\u001b[0;32m    656\u001b[0m     optimization_config\u001b[39m=\u001b[39moptimization_config,\n\u001b[0;32m    657\u001b[0m     pending_observations\u001b[39m=\u001b[39mpending_observations,\n\u001b[0;32m    658\u001b[0m     fixed_features\u001b[39m=\u001b[39mfixed_features,\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    661\u001b[0m \u001b[39m# Apply terminal transform and gen\u001b[39;00m\n\u001b[1;32m--> 662\u001b[0m gen_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gen(\n\u001b[0;32m    663\u001b[0m     n\u001b[39m=\u001b[39;49mn,\n\u001b[0;32m    664\u001b[0m     search_space\u001b[39m=\u001b[39;49mbase_gen_args\u001b[39m.\u001b[39;49msearch_space,\n\u001b[0;32m    665\u001b[0m     optimization_config\u001b[39m=\u001b[39;49mbase_gen_args\u001b[39m.\u001b[39;49moptimization_config,\n\u001b[0;32m    666\u001b[0m     pending_observations\u001b[39m=\u001b[39;49mbase_gen_args\u001b[39m.\u001b[39;49mpending_observations,\n\u001b[0;32m    667\u001b[0m     fixed_features\u001b[39m=\u001b[39;49mbase_gen_args\u001b[39m.\u001b[39;49mfixed_features,\n\u001b[0;32m    668\u001b[0m     model_gen_options\u001b[39m=\u001b[39;49mmodel_gen_options,\n\u001b[0;32m    669\u001b[0m )\n\u001b[0;32m    671\u001b[0m observation_features \u001b[39m=\u001b[39m gen_results\u001b[39m.\u001b[39mobservation_features\n\u001b[0;32m    672\u001b[0m best_obsf \u001b[39m=\u001b[39m gen_results\u001b[39m.\u001b[39mbest_observation_features\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\modelbridge\\torch.py:543\u001b[0m, in \u001b[0;36mTorchModelBridge._gen\u001b[1;34m(self, n, search_space, pending_observations, fixed_features, model_gen_options, optimization_config)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[39m# Generate the candidates\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[39m# TODO(ehotaj): For some reason, we're getting models which do not support MOO\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[39m# even when optimization_config has multiple objectives, so we can't use\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m# self.is_moo_problem here.\u001b[39;00m\n\u001b[0;32m    540\u001b[0m is_moo_problem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_moo_problem \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, (BoTorchModel, MultiObjectiveBotorchModel)\n\u001b[0;32m    542\u001b[0m )\n\u001b[1;32m--> 543\u001b[0m gen_results \u001b[39m=\u001b[39m not_none(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\u001b[39m.\u001b[39;49mgen(\n\u001b[0;32m    544\u001b[0m     n\u001b[39m=\u001b[39;49mn,\n\u001b[0;32m    545\u001b[0m     search_space_digest\u001b[39m=\u001b[39;49msearch_space_digest,\n\u001b[0;32m    546\u001b[0m     torch_opt_config\u001b[39m=\u001b[39;49mtorch_opt_config,\n\u001b[0;32m    547\u001b[0m )\n\u001b[0;32m    549\u001b[0m gen_metadata \u001b[39m=\u001b[39m gen_results\u001b[39m.\u001b[39mgen_metadata\n\u001b[0;32m    550\u001b[0m \u001b[39mif\u001b[39;00m is_moo_problem:\n\u001b[0;32m    551\u001b[0m     \u001b[39m# If objective_thresholds are supplied by the user, then the transformed\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[39m# user-specified objective thresholds are in gen_metadata. Otherwise,\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[39m# inferred objective thresholds are in gen_metadata.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\models\\torch\\botorch_modular\\model.py:255\u001b[0m, in \u001b[0;36mBoTorchModel.gen\u001b[1;34m(self, n, search_space_digest, torch_opt_config)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39m# update bounds / target fidelities\u001b[39;00m\n\u001b[0;32m    248\u001b[0m search_space_digest \u001b[39m=\u001b[39m not_none(\n\u001b[0;32m    249\u001b[0m     dataclasses\u001b[39m.\u001b[39mreplace(\n\u001b[0;32m    250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_space_digest,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    254\u001b[0m )\n\u001b[1;32m--> 255\u001b[0m acqf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_instantiate_acquisition(\n\u001b[0;32m    256\u001b[0m     search_space_digest\u001b[39m=\u001b[39;49msearch_space_digest,\n\u001b[0;32m    257\u001b[0m     torch_opt_config\u001b[39m=\u001b[39;49mtorch_opt_config,\n\u001b[0;32m    258\u001b[0m     acq_options\u001b[39m=\u001b[39;49macq_options,\n\u001b[0;32m    259\u001b[0m )\n\u001b[0;32m    260\u001b[0m botorch_rounding_func \u001b[39m=\u001b[39m get_rounding_func(torch_opt_config\u001b[39m.\u001b[39mrounding_func)\n\u001b[0;32m    261\u001b[0m candidates, expected_acquisition_value \u001b[39m=\u001b[39m acqf\u001b[39m.\u001b[39moptimize(\n\u001b[0;32m    262\u001b[0m     n\u001b[39m=\u001b[39mn,\n\u001b[0;32m    263\u001b[0m     search_space_digest\u001b[39m=\u001b[39msearch_space_digest,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     optimizer_options\u001b[39m=\u001b[39mchecked_cast(\u001b[39mdict\u001b[39m, opt_options),\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\models\\torch\\botorch_modular\\model.py:439\u001b[0m, in \u001b[0;36mBoTorchModel._instantiate_acquisition\u001b[1;34m(self, search_space_digest, torch_opt_config, acq_options)\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_botorch_acqf_class \u001b[39m=\u001b[39m choose_botorch_acqf_class(\n\u001b[0;32m    432\u001b[0m         pending_observations\u001b[39m=\u001b[39mtorch_opt_config\u001b[39m.\u001b[39mpending_observations,\n\u001b[0;32m    433\u001b[0m         outcome_constraints\u001b[39m=\u001b[39mtorch_opt_config\u001b[39m.\u001b[39moutcome_constraints,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    437\u001b[0m         objective_weights\u001b[39m=\u001b[39mtorch_opt_config\u001b[39m.\u001b[39mobjective_weights,\n\u001b[0;32m    438\u001b[0m     )\n\u001b[1;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49macquisition_class(\n\u001b[0;32m    440\u001b[0m     surrogate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurrogate,\n\u001b[0;32m    441\u001b[0m     botorch_acqf_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbotorch_acqf_class,\n\u001b[0;32m    442\u001b[0m     search_space_digest\u001b[39m=\u001b[39;49msearch_space_digest,\n\u001b[0;32m    443\u001b[0m     torch_opt_config\u001b[39m=\u001b[39;49mtorch_opt_config,\n\u001b[0;32m    444\u001b[0m     options\u001b[39m=\u001b[39;49macq_options,\n\u001b[0;32m    445\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\ax\\models\\torch\\botorch_modular\\acquisition.py:193\u001b[0m, in \u001b[0;36mAcquisition.__init__\u001b[1;34m(self, surrogate, search_space_digest, torch_opt_config, botorch_acqf_class, options)\u001b[0m\n\u001b[0;32m    183\u001b[0m     training_data \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m    184\u001b[0m         \u001b[39mzip\u001b[39m(not_none(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurrogate\u001b[39m.\u001b[39m_outcomes), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurrogate\u001b[39m.\u001b[39mtraining_data)\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    186\u001b[0m acqf_inputs \u001b[39m=\u001b[39m input_constructor(\n\u001b[0;32m    187\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    188\u001b[0m     training_data\u001b[39m=\u001b[39mtraining_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minput_constructor_kwargs,\n\u001b[0;32m    192\u001b[0m )\n\u001b[1;32m--> 193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macqf \u001b[39m=\u001b[39m botorch_acqf_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39macqf_inputs)  \u001b[39m# pyre-ignore [45]\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pending: Optional[Tensor] \u001b[39m=\u001b[39m X_pending\n\u001b[0;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_observed: Tensor \u001b[39m=\u001b[39m not_none(X_observed)\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\botorch\\acquisition\\active_learning.py:77\u001b[0m, in \u001b[0;36mqNegIntegratedPosteriorVariance.__init__\u001b[1;34m(self, model, mc_points, sampler, posterior_transform, X_pending, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     52\u001b[0m     model: Model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     58\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"q-Integrated Negative Posterior Variance.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m            have not yet been evaluated.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(model\u001b[39m=\u001b[39mmodel, posterior_transform\u001b[39m=\u001b[39mposterior_transform, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m sampler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39m# If no sampler is provided, we use the following dummy sampler for the\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         \u001b[39m# fantasize() method in forward. IMPORTANT: This assumes that the posterior\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[39m# variance does not depend on the samples y (only on x), which is true for\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         \u001b[39m# standard GP models, but not in general (e.g. for other likelihoods or\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[39m# heteroskedastic GPs using a separate noise model fit on data).\u001b[39;00m\n\u001b[0;32m     84\u001b[0m         sampler \u001b[39m=\u001b[39m SobolQMCNormalSampler(\n\u001b[0;32m     85\u001b[0m             num_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, resample\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, collapse_batch_dims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     86\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\botorch\\acquisition\\analytic.py:53\u001b[0m, in \u001b[0;36mAnalyticAcquisitionFunction.__init__\u001b[1;34m(self, model, posterior_transform, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Base constructor for analytic acquisition functions.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m        single-output posterior is required.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m---> 53\u001b[0m posterior_transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_deprecate_acqf_objective(\n\u001b[0;32m     54\u001b[0m     posterior_transform\u001b[39m=\u001b[39;49mposterior_transform,\n\u001b[0;32m     55\u001b[0m     objective\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mobjective\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m posterior_transform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mnum_outputs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\botorch\\acquisition\\acquisition.py:62\u001b[0m, in \u001b[0;36mAcquisitionFunction._deprecate_acqf_objective\u001b[1;34m(cls, posterior_transform, objective)\u001b[0m\n\u001b[0;32m     54\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     55\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m got a non-MC `objective`. The non-MC \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAcquisitionObjectives and the `objective` argument to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(objective, ScalarizedObjective):\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedError(\n\u001b[0;32m     63\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m only supports ScalarizedObjective \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(DEPRECATED) type objectives.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m \u001b[39mreturn\u001b[39;00m ScalarizedPosteriorTransform(\n\u001b[0;32m     67\u001b[0m     weights\u001b[39m=\u001b[39mobjective\u001b[39m.\u001b[39mweights, offset\u001b[39m=\u001b[39mobjective\u001b[39m.\u001b[39moffset\n\u001b[0;32m     68\u001b[0m )\n",
      "\u001b[1;31mUnsupportedError\u001b[0m: qNegIntegratedPosteriorVariance only supports ScalarizedObjective (DEPRECATED) type objectives."
     ]
    }
   ],
   "source": [
    "def evaluate(parameters):\n",
    "    data = sdl.observe_sensor_data(parameters)\n",
    "    new_data = {ch_name: data[ch_name] for ch_name in sdl.channel_names}\n",
    "    new_data[\"onboard_temperature_K\"] = data[\"onboard_temperature_K\"]\n",
    "    new_data[\"utc_timestamp\"] = data[\"utc_timestamp\"]\n",
    "    return new_data\n",
    "\n",
    "for _ in range(20):\n",
    "    trial_params, trial_index = ax_client.get_next_trial()\n",
    "    data = evaluate(trial_params)\n",
    "    ax_client.complete_trial(\n",
    "        trial_index=trial_index, raw_data=data\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdl-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70cb6d4911b67e25d1487ebd620c5d1370239efaaf47f3851af44f5c5a26f988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
