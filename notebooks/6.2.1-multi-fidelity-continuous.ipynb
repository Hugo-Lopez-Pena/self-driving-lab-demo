{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.1-multi-fidelity-continous.ipynb)\n",
    "# Continous Multi-fidelity Optimization with Knowledge Gradient\n",
    "\n",
    "In the previous notebook, I provided a brief introduction of multi-fidelity\n",
    "optimization in the context of the physical sciences. This notebook will cover\n",
    "Bayesian optimization using two continuous fidelity parameters (`atime` and `astep`). We'll compare the total integration time using the\n",
    "multi-fidelity optimization with the integration time costs of running the simulation at the\n",
    "the lowest fidelities, the highest fidelities (default), and approximately halfway in-between. For validation, the\n",
    "objective (in this case, `frechet`) will be evaluated at the upper bound of `atime` and `astep`. In\n",
    "this experiment, we'll allow `atime` to vary between `0..100` (upper limit is 255) which is:\n",
    "$2.78 \\mu s .. 280.78\\mu s$. We'll also allow `astep` to vary between `0..999` (upper\n",
    "limit is `65534`). In terms\n",
    "of physical integration time, this corresponds to lowest and highest integration times\n",
    "of $2.78 \\mu s$ and $281 ms$, respectively.\n",
    "\n",
    "For reference, here are the docs for `atime` and `astep` (taken from [`public_mqtt_sdl_demo/lib/as7341_sensor.py`](https://github.com/sparks-baird/self-driving-lab-demo/blob/main/src/public_mqtt_sdl_demo/lib/as7341_sensor.py)):\n",
    "```python\n",
    "\"\"\"\n",
    "...\n",
    "atime : int, optional\n",
    "    The integration time step size in 2.78 microsecond increments, by default 100\n",
    "astep : int, optional\n",
    "    The integration time step count. Total integration time will be (ATIME + 1)\n",
    "    * (ASTEP + 1) * 2.78ÂµS, by default 999, meaning 281 ms assuming atime=100\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "We'll be using the Knowledge Gradient (KG) acquisition function. \n",
    "\n",
    "From [the BoTorch docs](https://botorch.org/tutorials/one_shot_kg):\n",
    "> ### The one-shot Knowledge Gradient acquisition function\n",
    "> The Knowledge Gradient (KG) (see [2, 3]) is a look-ahead acquisition function that quantifies the expected increase in the maximum of the modeled black-box function f from obtaining additional (random) observations collected at the candidate set x. KG often shows improved Bayesian Optimization performance relative to simpler acquisition functions such as Expected Improvement, but in its traditional form it is computationally expensive and hard to implement.\n",
    ">\n",
    "> ...\n",
    "> \n",
    "> [2] P. Frazier, W. Powell, and S. Dayanik. A Knowledge-Gradient policy for sequential information collection. SIAM Journal on Control and Optimization, 2008.\n",
    "> \n",
    "> [3] J. Wu and P. Frazier. The parallel knowledge gradient method for batch bayesian optimization. NIPS 2016.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll still use Ax rather than delving into pure BoTorch code. Since\n",
    "Ax doesn't yet support discrete fidelity parameters, for the next notebook, we'll use\n",
    "BoTorch exclusively. BoTorch has [a tutorial for continuous multi-fidelity optimization](https://botorch.org/tutorials/multi_fidelity_bo#Multi-Fidelity-BO-in-BoTorch-with-Knowledge-Gradient)\n",
    "which has been [adapted for Ax in a GitHub\n",
    "issue](https://github.com/facebook/Ax/issues/475). We will largely base the\n",
    "implementation on the example from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we need to set up our `SelfDrivingLabDemo` classes. We will use the\n",
    "physical experimental setting since the simulations use only a simple multiplier to account for\n",
    "integration time. We'll also use the same `frechet` objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    %pip install self-driving-lab-demo\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session ID: 8cf2f2d7-1bd9-490a-aa40-3edc4681a60e\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4  # universally unique identifier\n",
    "from self_driving_lab_demo import SelfDrivingLabDemo, mqtt_observe_sensor_data\n",
    "\n",
    "dummy = True # @param {type:\"boolean\"}\n",
    "\n",
    "pico_id = \"test\"  # @param {type:\"string\"}\n",
    "if dummy:\n",
    "    num_repeats = 2\n",
    "    atime_max = 3\n",
    "    astep_max = 3\n",
    "else:\n",
    "    num_repeats = 5   # @param {type:\"integer\"}\n",
    "    atime_max = 100\n",
    "    astep_max = 999\n",
    "    \n",
    "simulation = True # @param {type:\"boolean\"}\n",
    "SESSION_ID = str(uuid4())  # random session ID\n",
    "\n",
    "def calc_integration_time_s(atime, astep):\n",
    "    return ((atime + 1) * (astep + 1) * 2.78) / 1e6\n",
    "\n",
    "# total seconds of integration time\n",
    "time_limit_s = 1 * calc_integration_time_s(atime_max, astep_max)\n",
    "seeds = range(10, 10 + num_repeats)\n",
    "print(f\"session ID: {SESSION_ID}\")\n",
    "\n",
    "sdls = [\n",
    "    SelfDrivingLabDemo(\n",
    "        autoload=True,  # perform target data experiment automatically\n",
    "        simulation=simulation,\n",
    "        observe_sensor_data_fn=mqtt_observe_sensor_data,  # (default)\n",
    "        observe_sensor_data_kwargs=dict(pico_id=pico_id, session_id=SESSION_ID),\n",
    "        target_seed=seed,\n",
    "    )\n",
    "    for seed in seeds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'R', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'G', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'B', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'atime',\n",
       "  'type': 'range',\n",
       "  'is_fidelity': True,\n",
       "  'bounds': [0, 3],\n",
       "  'target_value': 3}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = dict(R=sdls[0].bounds[\"R\"], G=sdls[0].bounds[\"G\"], B=sdls[0].bounds[\"B\"])\n",
    "params = [dict(name=nm, type=\"range\", bounds=bnd) for nm, bnd in bounds.items()]\n",
    "atime_bnd = [0, atime_max] # instead of [0, 255]\n",
    "astep_bnd = [0, astep_max] # instead of [0, 65534]\n",
    "params.append(\n",
    "    dict(\n",
    "        name=\"atime\",\n",
    "        type=\"range\",\n",
    "        is_fidelity=True,\n",
    "        bounds=atime_bnd,\n",
    "        target_value=atime_bnd[1],\n",
    "    )\n",
    ")\n",
    "# params.append(\n",
    "#     dict(\n",
    "#         name=\"astep\",\n",
    "#         type=\"range\",\n",
    "#         is_fidelity=True,\n",
    "#         bounds=astep_bnd,\n",
    "#         target_value=astep_bnd[1],\n",
    "#     )\n",
    "# )\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-15 23:33:42] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 10-15 23:33:42] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-15 23:33:42] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-15 23:33:42] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-15 23:33:42] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter atime. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-15 23:33:42] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89]), RangeParameter(name='atime', parameter_type=INT, range=[0, 3], fidelity=True, target_value=3)], parameter_constraints=[]).\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Generated new trial 0 with parameters {'R': 21, 'G': 76, 'B': 12, 'atime': 3}.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:42] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Completed trial 0 with data: {'mae': (34688.508493, None), 'rmse': (62354.631562, None), 'frechet': (161777.969037, None)}.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Generated new trial 1 with parameters {'R': 41, 'G': 43, 'B': 63, 'atime': 3}.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:42] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:42] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Completed trial 1 with data: {'mae': (34084.107718, None), 'rmse': (60804.497941, None), 'frechet': (158498.514442, None)}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Generated new trial 2 with parameters {'R': 72, 'G': 75, 'B': 15, 'atime': 0}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Completed trial 2 with data: {'mae': (35101.556393, None), 'rmse': (62684.546763, None), 'frechet': (163479.91313, None)}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Generated new trial 3 with parameters {'R': 51, 'G': 20, 'B': 78, 'atime': 1}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Completed trial 3 with data: {'mae': (34633.555606, None), 'rmse': (61613.92894, None), 'frechet': (160616.81285, None)}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Generated new trial 4 with parameters {'R': 20, 'G': 9, 'B': 57, 'atime': 0}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Completed trial 4 with data: {'mae': (35082.272236, None), 'rmse': (62426.491355, None), 'frechet': (162790.148664, None)}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Generated new trial 5 with parameters {'R': 83, 'G': 88, 'B': 11, 'atime': 2}.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric mae that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Data was logged for metric rmse that was not yet tracked on the experiment. Please specify `tracking_metric_names` argument in AxClient.create_experiment to add tracking metrics to the experiment. Without those, all data users specify is still attached to the experiment, but will not be fetched in `experiment.fetch_data()`, but you can still use `experiment.lookup_data_for_trial` to get all attached data.\n",
      "[INFO 10-15 23:33:43] ax.core.experiment: Attached data has some metrics ({'rmse', 'mae'}) that are not among the metrics on this experiment. Note that attaching data will not automatically add those metrics to the experiment. For these metrics to be automatically fetched by `experiment.fetch_data`, add them via `experiment.add_tracking_metric` or update the experiment's optimization config.\n",
      "[INFO 10-15 23:33:43] ax.service.ax_client: Completed trial 5 with data: {'mae': (34655.590346, None), 'rmse': (62367.027624, None), 'frechet': (162080.287167, None)}.\n",
      "c:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\botorch\\optim\\optimize.py:306: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 1.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 1.')]\n",
      "Because you specified `batch_initial_conditions`, optimization will not be retried with new initial conditions and will proceed with the current solution. Suggested remediation: Try again with different `batch_initial_conditions`, or don't provide `batch_initial_conditions.`\n",
      "  warnings.warn(first_warn_msg, RuntimeWarning)\n",
      "[INFO 10-15 23:34:41] ax.service.ax_client: Generated new trial 6 with parameters {'R': 35, 'G': 57, 'B': 79, 'atime': 0}.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'astep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m pi \u001b[39m=\u001b[39m q_p[q]\n\u001b[0;32m     61\u001b[0m ti \u001b[39m=\u001b[39m q_t[q]\n\u001b[1;32m---> 62\u001b[0m integration_time \u001b[39m=\u001b[39m calc_integration_time_s(pi[\u001b[39m\"\u001b[39m\u001b[39matime\u001b[39m\u001b[39m\"\u001b[39m], pi[\u001b[39m\"\u001b[39;49m\u001b[39mastep\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     63\u001b[0m running_integration_time_s \u001b[39m=\u001b[39m running_integration_time_s \u001b[39m+\u001b[39m integration_time\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m running_integration_time_s \u001b[39m>\u001b[39m time_limit_s:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'astep'"
     ]
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient\n",
    "from botorch.test_functions.multi_fidelity import AugmentedHartmann\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "import torch\n",
    "\n",
    "integration_time_name = \"integration_time_s\"\n",
    "ax_clients = []\n",
    "batch_size = 1\n",
    "num_sobol = 6\n",
    "objectives = {\"frechet\": ObjectiveProperties(minimize=True)}\n",
    "\n",
    "for sdl in sdls:\n",
    "\n",
    "    def evaluate(parameters):\n",
    "        R = parameters[\"R\"]\n",
    "        G = parameters[\"G\"]\n",
    "        B = parameters[\"B\"]\n",
    "        atime = parameters[\"atime\"]\n",
    "        # astep = parameters[\"astep\"]\n",
    "        # results = sdl.evaluate(R=R, G=G, B=B, atime=atime, astep=astep)\n",
    "        results = sdl.evaluate(R=R, G=G, B=B, atime=atime)\n",
    "        # results[integration_time_name] = calc_integration_time_s(atime, astep)\n",
    "        # remove channel names to prevent extra tracking metrics warnings\n",
    "        [results.pop(ch) for ch in sdl.channel_names]\n",
    "        return results\n",
    "\n",
    "    gs = GenerationStrategy(\n",
    "        steps=[\n",
    "            GenerationStep(model=Models.SOBOL, num_trials=num_sobol),\n",
    "            GenerationStep(model=Models.GPKG, num_trials=-1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ax_client = AxClient(generation_strategy=gs)\n",
    "    ax_client.create_experiment(\n",
    "        name=\"sdl_demo_mf_experiment\",\n",
    "        parameters=params,\n",
    "        objectives=objectives,\n",
    "        tracking_metric_names=[integration_time_name],\n",
    "        overwrite_existing_experiment=True,\n",
    "    )\n",
    "    \n",
    "    running_integration_time_s = 0\n",
    "    # Initial sobol samples\n",
    "    for i in range(num_sobol):\n",
    "        parameters, trial_index = ax_client.get_next_trial()\n",
    "        ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))\n",
    "\n",
    "    # KGBO\n",
    "    while running_integration_time_s < time_limit_s:\n",
    "        q_p, q_t = [], []\n",
    "        # Simulate batches\n",
    "        for q in range(batch_size):\n",
    "            parameters, trial_index = ax_client.get_next_trial()\n",
    "            q_p.append(parameters)\n",
    "            q_t.append(trial_index)\n",
    "        for q in range(batch_size):\n",
    "            pi = q_p[q]\n",
    "            ti = q_t[q]\n",
    "            integration_time = calc_integration_time_s(pi[\"atime\"], pi[\"astep\"])\n",
    "            running_integration_time_s = running_integration_time_s + integration_time\n",
    "            if running_integration_time_s > time_limit_s:\n",
    "                break\n",
    "            ax_client.complete_trial(trial_index=ti, raw_data=evaluate(pi))\n",
    "        \n",
    "        if running_integration_time_s > time_limit_s:\n",
    "            break\n",
    "    \n",
    "    ax_clients.append(ax_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdl-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70cb6d4911b67e25d1487ebd620c5d1370239efaaf47f3851af44f5c5a26f988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
